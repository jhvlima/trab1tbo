# Trabalho 1 - TBO

# Para fazer o teste e ver as diferancas na saida
./testador both
./comparador

Padr√£o de execu√ß√£o do execut√°vel
```bash
make
./trab1 entrada.txt saida.txt
```

Exemplo de execu√ß√£o
```bash
make
./main casos_teste_v3/caso_teste_muito_pequeno_1.txt saidas/saida_caso_teste_muito_pequeno_1.txt
```

# Disposi√ß√£o do reposit√≥rio
    .
    ‚îú‚îÄ‚îÄ casos_teste_v3
    ‚îÇ   ‚îú‚îÄ‚îÄ caso_teste_medio_1.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ caso_teste_medio_2.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ caso_teste_medio_3.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ caso_teste_medio_4.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ caso_teste_muito_pequeno_1.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ caso_teste_muito_pequeno_2.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ caso_teste_pequeno_1.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ caso_teste_pequeno_2.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ caso_teste_pequeno_3.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ caso_teste_pequeno_4.txt
    ‚îú‚îÄ‚îÄ mainHeap
    ‚îú‚îÄ‚îÄ mainMatrix
    ‚îú‚îÄ‚îÄ makefile
    ‚îú‚îÄ‚îÄ obj
    ‚îÇ   ‚îú‚îÄ‚îÄ dijkstraHeap.o
    ‚îÇ   ‚îú‚îÄ‚îÄ dijkstraMatrix.o
    ‚îÇ   ‚îú‚îÄ‚îÄ graph.o
    ‚îÇ   ‚îú‚îÄ‚îÄ heap.o
    ‚îÇ   ‚îú‚îÄ‚îÄ ioHandler.o
    ‚îÇ   ‚îú‚îÄ‚îÄ mainHeap.o
    ‚îÇ   ‚îú‚îÄ‚îÄ mainMatrix.o
    ‚îÇ   ‚îú‚îÄ‚îÄ matrix.o
    ‚îÇ   ‚îî‚îÄ‚îÄ node.o
    ‚îú‚îÄ‚îÄ readme.md
    ‚îú‚îÄ‚îÄ saidas
    ‚îÇ   ‚îú‚îÄ‚îÄ saida_caso_teste_medio_1.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ saida_caso_teste_medio_2.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ saida_caso_teste_medio_3.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ saida_caso_teste_medio_4.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ saida_caso_teste_muito_pequeno_1.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ saida_caso_teste_muito_pequeno_2.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ saida_caso_teste_pequeno_1.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ saida_caso_teste_pequeno_2.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ saida_caso_teste_pequeno_3.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ saida_caso_teste_pequeno_4.txt
    ‚îú‚îÄ‚îÄ src
    ‚îÇ   ‚îú‚îÄ‚îÄ dijkstraHeap.c
    ‚îÇ   ‚îú‚îÄ‚îÄ dijkstraHeap.h
    ‚îÇ   ‚îú‚îÄ‚îÄ dijkstraMatrix.c
    ‚îÇ   ‚îú‚îÄ‚îÄ dijkstraMatrix.h
    ‚îÇ   ‚îú‚îÄ‚îÄ graph.c
    ‚îÇ   ‚îú‚îÄ‚îÄ graph.h
    ‚îÇ   ‚îú‚îÄ‚îÄ heap.c
    ‚îÇ   ‚îú‚îÄ‚îÄ heap.h
    ‚îÇ   ‚îú‚îÄ‚îÄ ioHandler.c
    ‚îÇ   ‚îú‚îÄ‚îÄ ioHandler.h
    ‚îÇ   ‚îú‚îÄ‚îÄ mainHeap.c
    ‚îÇ   ‚îú‚îÄ‚îÄ mainMatrix.c
    ‚îÇ   ‚îú‚îÄ‚îÄ matrix.c
    ‚îÇ   ‚îú‚îÄ‚îÄ matrix.h
    ‚îÇ   ‚îú‚îÄ‚îÄ node.c
    ‚îÇ   ‚îî‚îÄ‚îÄ node.h
    ‚îú‚îÄ‚îÄ T1_2024_2_especificacao_v2.pdf
    ‚îî‚îÄ‚îÄ testador.sh


## Introdu√ß√£o

Este relat√≥rio compara o uso de mem√≥ria, tempo de execu√ß√£o e complexidade entre duas implementa√ß√µes do algoritmo de Dijkstra: uma utilizando uma MinHeap e outra utilizando uma matriz de adjac√™ncias dinamicamente alocadas.

## An√°lise de Complexidade

### Implementa√ß√£o com Heap
Cria√ß√£o da Heap (heapCreate)	
ùëÇ(ùëâ)	Inicializa a heap com ùëâ v√©rtices.

Inser√ß√£o na Heap (heapPush)	ùëÇ(log‚Å°ùëâ)	
Cada inser√ß√£o na MinHeap leva ùëÇ(log‚Å°ùëâ).

Extra√ß√£o do M√≠nimo (heapPopMin)	ùëÇ(log‚Å°ùëâ)	
A cada itera√ß√£o, o n√≥ com menor dist√¢ncia √© removido da MinHeap.

Atualiza√ß√£o de dist√¢ncia (heapAtualizaDistancia)	ùëÇ(log‚Å°ùëâ)	
A cada relaxamento, a dist√¢ncia do n√≥ pode ser atualizada e a heap reordenada.

Itera√ß√£o sobre todas as arestas	ùëÇ(ùê∏)
O loop interno percorre todas as arestas uma vez.

Total 
O(V log V + E log V) = O((V+E) log V) 

Como em um grafo denso,  ùê∏ pode ser pr√≥ximo de  ùëâ 2 V  2  , o pior caso pode ser  ùëÇ ( ùëâ 2 log ‚Å° ùëâ ) O(V  2  logV). Mas para grafos esparsos (onde  ùê∏ ‚âà ùëâ E‚âàV), a complexidade se aproxima de  ùëÇ ( ùëâ log ‚Å° ùëâ ) O(VlogV).

### 1. **Cria√ß√£o da Heap (heapCreate)**
- **Complexidade: ùëÇ(ùëâ)**
  - Inicializar a heap com ùëâ v√©rtices envolve inserir todos os v√©rtices na heap com uma dist√¢ncia inicial (geralmente infinita, exceto para o v√©rtice de origem, que tem dist√¢ncia 0).
  - Isso pode ser feito em ùëÇ(ùëâ) se a heap for constru√≠da de forma eficiente (por exemplo, usando o algoritmo de Floyd para construir uma heap em tempo linear).

---

### 2. **Inser√ß√£o na Heap (heapPush)**
- **Complexidade: ùëÇ(log ùëâ)**
  - Cada inser√ß√£o na MinHeap leva ùëÇ(log ùëâ), pois a heap deve manter sua propriedade de ordem ap√≥s a inser√ß√£o.

---

### 3. **Extra√ß√£o do M√≠nimo (heapPopMin)**
- **Complexidade: ùëÇ(log ùëâ)**
  - A cada itera√ß√£o do algoritmo de Dijkstra, o v√©rtice com a menor dist√¢ncia √© extra√≠do da heap. Isso requer ùëÇ(log ùëâ) para manter a propriedade da heap ap√≥s a remo√ß√£o.

---

### 4. **Atualiza√ß√£o de Dist√¢ncia (heapAtualizaDistancia)**
- **Complexidade: ùëÇ(log ùëâ)**
  - Quando a dist√¢ncia de um v√©rtice √© atualizada (relaxamento), sua posi√ß√£o na heap pode mudar. Isso requer ùëÇ(log ùëâ) para reordenar a heap.

---

### 5. **Itera√ß√£o sobre Todas as Arestas**
- **Complexidade: ùëÇ(ùê∏)**
  - O loop interno do algoritmo de Dijkstra percorre todas as arestas do grafo uma vez. Para cada aresta, pode ser necess√°rio atualizar a dist√¢ncia de um v√©rtice na heap.

---

### 6. **Complexidade Total**
A complexidade total do algoritmo de Dijkstra com uma MinHeap √© a soma das opera√ß√µes acima:
- **Inicializa√ß√£o:** ùëÇ(ùëâ)
- **Opera√ß√µes de Heap (inser√ß√£o, extra√ß√£o, atualiza√ß√£o):** ùëÇ((ùëâ + ùê∏) log ùëâ)
  - Cada v√©rtice √© extra√≠do uma vez (ùëâ opera√ß√µes de extra√ß√£o).
  - Cada aresta pode levar a uma atualiza√ß√£o na heap (ùê∏ opera√ß√µes de atualiza√ß√£o).
- **Itera√ß√£o sobre arestas:** ùëÇ(ùê∏)

Portanto, a complexidade total √©:
\[
ùëÇ(ùëâ) + ùëÇ((ùëâ + ùê∏) \log ùëâ) = ùëÇ((ùëâ + ùê∏) \log ùëâ)
\]

---

### 7. **An√°lise para Grafos Densos e Esparsos**
- **Grafos Densos (ùê∏ ‚âà ùëâ¬≤):**
  \[
  ùëÇ((ùëâ + ùëâ¬≤) \log ùëâ) = ùëÇ(ùëâ¬≤ \log ùëâ)
  \]
  - Neste caso, o termo dominante √© ùëâ¬≤, pois o n√∫mero de arestas √© grande.

- **Grafos Esparsos (ùê∏ ‚âà ùëâ):**
  \[
  ùëÇ((ùëâ + ùëâ) \log ùëâ) = ùëÇ(ùëâ \log ùëâ)
  \]
  - Aqui, o termo dominante √© ùëâ, pois o n√∫mero de arestas √© proporcional ao n√∫mero de v√©rtices.

---

### 8. **Compara√ß√£o com Outras Implementa√ß√µes**
- **Sem Heap (usando lista simples):**
  - Complexidade: ùëÇ(ùëâ¬≤)
  - Adequado para grafos densos, mas ineficiente para grafos esparsos.

- **Com Heap Bin√°ria:**
  - Complexidade: ùëÇ((ùëâ + ùê∏) \log ùëâ)
  - Mais eficiente para grafos esparsos.

- **Com Heap de Fibonacci:**
  - Complexidade: ùëÇ(ùëâ \log ùëâ + ùê∏)
  - Ainda mais eficiente, mas com overhead maior na implementa√ß√£o.

---

### Conclus√£o
A implementa√ß√£o do algoritmo de Dijkstra com uma **MinHeap** √© eficiente para grafos esparsos, com complexidade ùëÇ((ùëâ + ùê∏) \log ùëâ). Para grafos densos, a complexidade se aproxima de ùëÇ(ùëâ¬≤ \log ùëâ), o que ainda √© melhor do que a implementa√ß√£o sem heap (ùëÇ(ùëâ¬≤)). A escolha da estrutura de dados depende do tipo de grafo e dos requisitos de desempenho.

### Implementa√ß√£o com Matrix
Matrix* matrix -> V(float + char)
int* pais -> [V]
float* distancias -> [V]
Node** arvoreMin -> maximo V


Inicializa estruturas:
arvoreMin para armazenar os n√≥s processados.
pais para armazenar os pais dos n√≥s.
distancias para armazenar a menor dist√¢ncia encontrada at√© cada n√≥.
Define todas as dist√¢ncias como -1 (infinito), exceto a do n√≥ de origem (distancias[source] = 0).
Para cada itera√ß√£o:
Extrai o n√≥ com a menor dist√¢ncia (extraiMin).
Define o pai do n√≥ na √°rvore m√≠nima.
Relaxa as arestas dos vizinhos (relaxarArestas).
Libera mem√≥ria para pais e distancias, e retorna a √°rvore m√≠nima.

## Testes

Os testes foram executados utilizando o Valgrind para monitorar o uso de mem√≥ria e sem o valgrind para computar os tempos de execu√ß√£o. Os tempos s√£o uma m√©dia de 10 execu√ß√µes. Os seguintes comandos foram utilizados para executar os testes:

```bash
testador.sh both                # tem a saida dos tempos de execucao no terminal
testador.sh both valgrind       # tem a saida do valgrind nos logs no diretorio 'saidas/' 
```

### Resuldados da Implementa√ß√£o com Heap

| Caso de Teste                     | Total Heap Usage (bytes) | In Use at Exit (bytes) | Total Allocs | Tempo de Execu√ß√£o (segundos) |
|-----------------------------------|--------------------------|------------------------|--------------|-----------------------------|
| caso_teste_muito_pequeno_1.txt    | 11,123                   | 0                      | 42           | 0.009915                    |
| caso_teste_muito_pequeno_2.txt    | 11,959                   | 0                      | 77           | 0.005652                    |
| caso_teste_pequeno_1.txt          | 9,812                    | 0                      | 249,026      | 0.029793                    |
| caso_teste_pequeno_2.txt          | 9,880                    | 0                      | 250,658      | 0.011586                    |
| caso_teste_pequeno_3.txt          | 954,613                  | 0                      | 22,978,858   | 0.269650                    |
| caso_teste_pequeno_4.txt          | 955,011                  | 0                      | 22,988,410   | 0.270477                    |
| caso_teste_medio_1.txt            | 571,843,978              | 0                      | 23,815,481   | 6.283894                    |
| caso_teste_medio_2.txt            | 571,875,514              | 0                      | 23,816,795   | 6.109730                    |
| caso_teste_medio_3.txt            | 571,869,034              | 0                      | 23,816,525   | 5.970471                    |
| caso_teste_medio_4.txt            | 823,425,570              | 0                      | 34,297,964   | 8.739837                    |

### Resultados da Implementa√ß√£o com Matrix

| Caso de Teste                     | Total Heap Usage (bytes) | In Use at Exit (bytes) | Total Allocs | Tempo de Execu√ß√£o (segundos) |
|-----------------------------------|--------------------------|------------------------|--------------|-----------------------------|
| caso_teste_muito_pequeno_1.txt    | 10,779                   | 0                      | 28           | 0.005019                    |
| caso_teste_muito_pequeno_2.txt    | 11,207                   | 0                      | 40           | 0.006240                    |
| caso_teste_pequeno_1.txt          | 59,114                   | 0                      | 316          | 0.013385                    |
| caso_teste_pequeno_2.txt          | 59,114                   | 0                      | 316          | 0.006920                    |
| caso_teste_pequeno_3.txt          | 4,120,594                | 0                      | 3,019        | 0.202453                    |
| caso_teste_pequeno_4.txt          | 4,120,594                | 0                      | 3,019        | 0.188479                    |
| caso_teste_medio_1.txt            | 100,532,978              | 0                      | 15,023       | 3.639112                    |
| caso_teste_medio_2.txt            | 100,532,978              | 0                      | 15,023       | 4.056108                    |
| caso_teste_medio_3.txt            | 100,532,978              | 0                      | 15,023       | 3.612667                    |
| caso_teste_medio_4.txt            | 144,586,978              | 0                      | 18,023       | 5.467426                    |

## Conclus√£o
De acordo com os dados das tabelas acima percebe-se que na maioria dos casos a implementa√ß√£o Matrix √© mais r√°pida e usa menos aloca√ß√£o de mem√≥ria na maioria dos casos de teste, com exe√ß√£o do uso da heap nos casos pequenos. Essa superioridade no desenpenho da implementa√ß√£o de matriz de adjascencias se deve por conta da entrada dos casos de teste, uma vez que os grafos passados eram densos, ou seja, E ‚âà V¬≤ , dessa forma 
